{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12486502,"sourceType":"datasetVersion","datasetId":7879217}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:10.629349Z","iopub.execute_input":"2025-07-23T13:27:10.629613Z","iopub.status.idle":"2025-07-23T13:27:13.057061Z","shell.execute_reply.started":"2025-07-23T13:27:10.629583Z","shell.execute_reply":"2025-07-23T13:27:13.056015Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/train_medicine_first_strategy.tsv\n/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/train_wikicorpus_second_strategy.tsv\n/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/test_medicine.tsv\n/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/train_medicine_second_strategy.tsv\n/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/train_wikicorpus_first_strategy.tsv\n/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/test_wikicorpus.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def head_of_tsv(file_path, num_lines=5):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for _ in range(num_lines):\n            print(file.readline().strip().split('\\t'))\n\nhead_of_tsv('/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output/test_wikicorpus.tsv', 5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:13.058135Z","iopub.execute_input":"2025-07-23T13:27:13.058566Z","iopub.status.idle":"2025-07-23T13:27:13.070819Z","shell.execute_reply.started":"2025-07-23T13:27:13.058537Z","shell.execute_reply":"2025-07-23T13:27:13.070150Z"}},"outputs":[{"name":"stdout","text":"['source', 'target']\n['La iglesia contiene numerosas obras de harte', 'La iglesia contiene numerosas obras de arte']\n['Otras obras notables shon las pinturas del Cavalier d Arpino La Virgen María con los santos Francisco de Asís y Agustín y el altar con la Misa de San Gregorio , de Jacopo Zucchi', 'Otras obras notables son las pinturas del Cavalier d Arpino La Virgen María con los santos Francisco de Asís y Agustín y el altar con la Misa de San Gregorio , de Jacopo Zucchi']\n['En esta parroquia tamvién desarrolla alguna de sus actividades la Comunidad de Sant Egidio', 'En esta parroquia también desarrolla alguna de sus actividades la Comunidad de Sant Egidio']\n['Página oficia ; ENDOFARTICLE', 'Página oficial ; ENDOFARTICLE']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom datasets import Dataset, load_dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSeq2SeqLM, \n    TrainingArguments, \n    Trainer,\n    DataCollatorForSeq2Seq\n)\nfrom tqdm import tqdm\nimport logging","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:13.073619Z","iopub.execute_input":"2025-07-23T13:27:13.074311Z","iopub.status.idle":"2025-07-23T13:27:53.860812Z","shell.execute_reply.started":"2025-07-23T13:27:13.074282Z","shell.execute_reply":"2025-07-23T13:27:53.860115Z"}},"outputs":[{"name":"stderr","text":"2025-07-23 13:27:35.498890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753277255.837957      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753277255.939593      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:53.861672Z","iopub.execute_input":"2025-07-23T13:27:53.862344Z","iopub.status.idle":"2025-07-23T13:27:53.866604Z","shell.execute_reply.started":"2025-07-23T13:27:53.862318Z","shell.execute_reply":"2025-07-23T13:27:53.865809Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Configuration\nMODEL_NAME = \"jorgeortizfuentes/spanish-spellchecker-t5-base-wiki200000\"\nDATA_DIR = \"/kaggle/input/wiki-med-esp/kaggle_outputs/tsv_output\"\nOUTPUT_DIR = \"./fine_tuned_t5_spellchecker\"\nMAX_LENGTH = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:53.867459Z","iopub.execute_input":"2025-07-23T13:27:53.867773Z","iopub.status.idle":"2025-07-23T13:27:53.924323Z","shell.execute_reply.started":"2025-07-23T13:27:53.867745Z","shell.execute_reply":"2025-07-23T13:27:53.923413Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 🔥 TESTING MODE: Set fraction of data to use (0.1 = 10%, 1.0 = 100%)\nDATA_FRACTION = 1.0  # Change this to control data size\nUSE_FRACTION = True  # Set to False to use full dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:53.925286Z","iopub.execute_input":"2025-07-23T13:27:53.925593Z","iopub.status.idle":"2025-07-23T13:27:53.941379Z","shell.execute_reply.started":"2025-07-23T13:27:53.925559Z","shell.execute_reply":"2025-07-23T13:27:53.940635Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Training files to use (first strategy only)\nTRAIN_FILES = [\n    \"train_medicine_first_strategy.tsv\",\n    \"train_wikicorpus_first_strategy.tsv\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:53.942338Z","iopub.execute_input":"2025-07-23T13:27:53.942968Z","iopub.status.idle":"2025-07-23T13:27:53.960343Z","shell.execute_reply.started":"2025-07-23T13:27:53.942929Z","shell.execute_reply":"2025-07-23T13:27:53.959416Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"🚀 Starting T5 Spanish Spellchecker Fine-tuning\")\nif USE_FRACTION:\n    print(f\"🧪 TESTING MODE: Using {DATA_FRACTION*100}% of data\")\nelse:\n    print(\"📊 FULL MODE: Using complete dataset\")\nprint(\"=\" * 60)\n\n# 1. Load tokenizer and model\nprint(\"📥 Loading tokenizer and model...\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:27:53.961513Z","iopub.execute_input":"2025-07-23T13:27:53.961827Z","iopub.status.idle":"2025-07-23T13:28:00.505439Z","shell.execute_reply.started":"2025-07-23T13:27:53.961798Z","shell.execute_reply":"2025-07-23T13:28:00.504662Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting T5 Spanish Spellchecker Fine-tuning\n🧪 TESTING MODE: Using 100.0% of data\n============================================================\n📥 Loading tokenizer and model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dedc166eae03479a9fc3b5b858a84660"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e57b6e3e4254f86af7834b1e2bf4899"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca0b76566d8a466bb4874e8e321d2742"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c91ca8870ab14fdca971d397da9dcad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c087bbbf96ba476fb6d030be2722fcd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"feadcec133784662ad99cff930e5e0d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8a9c34af2f64658a7bf4bcc12fda951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"410f94bd28d845f389b816cc78ede48d"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Ensure model is in training mode\nmodel.train()\nprint(f\"✅ Model loaded: {MODEL_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:28:00.508108Z","iopub.execute_input":"2025-07-23T13:28:00.508339Z","iopub.status.idle":"2025-07-23T13:28:00.515276Z","shell.execute_reply.started":"2025-07-23T13:28:00.508322Z","shell.execute_reply":"2025-07-23T13:28:00.514253Z"}},"outputs":[{"name":"stdout","text":"✅ Model loaded: jorgeortizfuentes/spanish-spellchecker-t5-base-wiki200000\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 2. Load and prepare dataset\nprint(\"\\n📊 Loading dataset files...\")\nall_data = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:28:00.516110Z","iopub.execute_input":"2025-07-23T13:28:00.516315Z","iopub.status.idle":"2025-07-23T13:28:00.538609Z","shell.execute_reply.started":"2025-07-23T13:28:00.516298Z","shell.execute_reply":"2025-07-23T13:28:00.537249Z"}},"outputs":[{"name":"stdout","text":"\n📊 Loading dataset files...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"for file_name in TRAIN_FILES:\n    file_path = os.path.join(DATA_DIR, file_name)\n    if os.path.exists(file_path):\n        print(f\"Loading {file_name}...\")\n        df = pd.read_csv(file_path, delimiter='\\t')\n        \n        # Drop rows with missing values\n        df = df.dropna()\n        \n        print(f\"  - {file_name}: {len(df)} samples\")\n        all_data.append(df)\n    else:\n        print(f\"❌ Warning: {file_path} not found!\")\n\n# Concatenate all data\nif all_data:\n    combined_df = pd.concat(all_data, ignore_index=True)\n    print(f\"\\n📈 Total combined samples: {len(combined_df)}\")\n    \n    # 🔥 Apply data fraction if enabled\n    if USE_FRACTION and DATA_FRACTION < 1.0:\n        original_size = len(combined_df)\n        # Shuffle and take fraction\n        combined_df = combined_df.sample(frac=DATA_FRACTION, random_state=42).reset_index(drop=True)\n        print(f\"🧪 TESTING MODE: Using {DATA_FRACTION*100}% of data\")\n        print(f\"   Reduced from {original_size} to {len(combined_df)} samples\")\n    else:\n        print(f\"📊 Using full dataset: {len(combined_df)} samples\")\n        \nelse:\n    raise FileNotFoundError(\"No training files found!\")\n\n# Convert to dataset\ndataset = Dataset.from_pandas(combined_df)\nprint(f\"✅ Dataset created with {len(dataset)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:28:00.539870Z","iopub.execute_input":"2025-07-23T13:28:00.540731Z","iopub.status.idle":"2025-07-23T13:29:42.192576Z","shell.execute_reply.started":"2025-07-23T13:28:00.540709Z","shell.execute_reply":"2025-07-23T13:29:42.191947Z"}},"outputs":[{"name":"stdout","text":"Loading train_medicine_first_strategy.tsv...\n  - train_medicine_first_strategy.tsv: 156089 samples\nLoading train_wikicorpus_first_strategy.tsv...\n  - train_wikicorpus_first_strategy.tsv: 9755938 samples\n\n📈 Total combined samples: 9912027\n📊 Using full dataset: 9912027 samples\n✅ Dataset created with 9912027 samples\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 3. Tokenization function\ndef tokenize_function(examples):\n    # Tokenize inputs (source - noisy text)\n    model_inputs = tokenizer(\n        examples[\"source\"], \n        max_length=MAX_LENGTH, \n        truncation=True, \n        padding=False  # Don't pad during tokenization\n    )\n    \n    # Tokenize targets (target - clean text) - using text_target parameter\n    labels = tokenizer(\n        text_target=examples[\"target\"], \n        max_length=MAX_LENGTH, \n        truncation=True, \n        padding=False  # Don't pad during tokenization\n    )\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:29:42.193392Z","iopub.execute_input":"2025-07-23T13:29:42.193635Z","iopub.status.idle":"2025-07-23T13:29:42.198411Z","shell.execute_reply.started":"2025-07-23T13:29:42.193607Z","shell.execute_reply":"2025-07-23T13:29:42.197777Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# 4. Apply tokenization\nprint(\"\\n🔄 Tokenizing dataset...\")\ntokenized_dataset = dataset.map(\n    tokenize_function, \n    batched=True,\n    batch_size=4000,  # Process in larger batches\n    remove_columns=dataset.column_names,\n    num_proc=1  # Single process to avoid issues\n)\n\nprint(f\"✅ Tokenization completed!\")\nprint(f\"Dataset size: {len(tokenized_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:29:42.199212Z","iopub.execute_input":"2025-07-23T13:29:42.199482Z","iopub.status.idle":"2025-07-23T13:57:29.904025Z","shell.execute_reply.started":"2025-07-23T13:29:42.199459Z","shell.execute_reply":"2025-07-23T13:57:29.903210Z"}},"outputs":[{"name":"stdout","text":"\n🔄 Tokenizing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9912027 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1531bb3a8d364b7e9789a3cda16ef2d2"}},"metadata":{}},{"name":"stdout","text":"✅ Tokenization completed!\nDataset size: 9912027\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# # Log token statistics\n# sample_size = min(100, len(tokenized_dataset))\n# sample_input_lengths = [len(x) for x in tokenized_dataset[\"input_ids\"][:sample_size]]\n# sample_label_lengths = [len(x) for x in tokenized_dataset[\"labels\"][:sample_size]]\n\n# print(f\"📊 Token Statistics (first {sample_size} samples):\")\n# print(f\"  - Input length: min={min(sample_input_lengths)}, max={max(sample_input_lengths)}, avg={sum(sample_input_lengths)/len(sample_input_lengths):.1f}\")\n# print(f\"  - Label length: min={min(sample_label_lengths)}, max={max(sample_label_lengths)}, avg={sum(sample_label_lengths)/len(sample_label_lengths):.1f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:29.904780Z","iopub.execute_input":"2025-07-23T13:57:29.905022Z","iopub.status.idle":"2025-07-23T13:57:29.909038Z","shell.execute_reply.started":"2025-07-23T13:57:29.905005Z","shell.execute_reply":"2025-07-23T13:57:29.908239Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# 5. Data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=model,\n    padding=True\n)\n\n# 6. Training arguments\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    eval_strategy=\"no\",\n    logging_steps=20 if USE_FRACTION else 50,\n    save_steps=100 if USE_FRACTION else 500,\n    save_total_limit=2,\n    per_device_train_batch_size=16,\n    gradient_accumulation_steps=2,\n    num_train_epochs=2 if USE_FRACTION else 3,\n    warmup_steps=50 if USE_FRACTION else 100,\n    weight_decay=0.01,\n    logging_dir=f\"{OUTPUT_DIR}/logs\",\n    save_strategy=\"steps\",\n    report_to=[],  # Empty list instead of None\n    dataloader_num_workers=0,\n    remove_unused_columns=False,\n    push_to_hub=False,\n    fp16=False,\n    dataloader_pin_memory=False,\n    run_name=\"t5_spellchecker_training\",  # Explicit run name\n    disable_tqdm=False,  # Keep progress bars\n)\n\n# 7. Initialize trainer\nprint(\"\\n🏋️ Initializing trainer...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:59:30.641674Z","iopub.execute_input":"2025-07-23T13:59:30.642292Z","iopub.status.idle":"2025-07-23T13:59:30.677584Z","shell.execute_reply.started":"2025-07-23T13:59:30.642267Z","shell.execute_reply":"2025-07-23T13:59:30.677038Z"}},"outputs":[{"name":"stdout","text":"\n🏋️ Initializing trainer...\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Create output directory if it doesn't exist\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    processing_class=tokenizer,  # Use processing_class instead of tokenizer\n    data_collator=data_collator,\n)\n\nprint(\"✅ Trainer initialized successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:59:37.936080Z","iopub.execute_input":"2025-07-23T13:59:37.936379Z","iopub.status.idle":"2025-07-23T13:59:37.951862Z","shell.execute_reply.started":"2025-07-23T13:59:37.936359Z","shell.execute_reply":"2025-07-23T13:59:37.951307Z"}},"outputs":[{"name":"stdout","text":"✅ Trainer initialized successfully!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# 8. Start training\nprint(\"\\n🚀 Starting training...\")\nprint(f\"Total training samples: {len(tokenized_dataset)}\")\nprint(f\"Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"Gradient accumulation steps: {training_args.gradient_accumulation_steps}\")\nprint(f\"Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\nprint(f\"Epochs: {training_args.num_train_epochs}\")\n\nsteps_per_epoch = len(tokenized_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\ntotal_steps = steps_per_epoch * training_args.num_train_epochs\nprint(f\"Steps per epoch: {steps_per_epoch}\")\nprint(f\"Total steps: {total_steps}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:59:41.871273Z","iopub.execute_input":"2025-07-23T13:59:41.871819Z","iopub.status.idle":"2025-07-23T13:59:41.876868Z","shell.execute_reply.started":"2025-07-23T13:59:41.871796Z","shell.execute_reply":"2025-07-23T13:59:41.876112Z"}},"outputs":[{"name":"stdout","text":"\n🚀 Starting training...\nTotal training samples: 9912027\nBatch size: 16\nGradient accumulation steps: 2\nEffective batch size: 32\nEpochs: 2\nSteps per epoch: 309750\nTotal steps: 619500\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Disable wandb if it's trying to initialize\nos.environ['WANDB_DISABLED'] = 'true'\n\nprint(\"\\n⏳ Training started - this may take a while...\")\ntry:\n    trainer.train()\n    print(\"✅ Training completed successfully!\")\nexcept Exception as e:\n    print(f\"❌ Training failed: {str(e)}\")\n    import traceback\n    traceback.print_exc()\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:59:43.601089Z","iopub.execute_input":"2025-07-23T13:59:43.601406Z","iopub.status.idle":"2025-07-23T14:08:15.278756Z","shell.execute_reply.started":"2025-07-23T13:59:43.601386Z","shell.execute_reply":"2025-07-23T14:08:15.277269Z"}},"outputs":[{"name":"stdout","text":"\n⏳ Training started - this may take a while...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='229' max='309752' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   229/309752 08:25 < 191:26:00, 0.45 it/s, Epoch 0.00/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.197700</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.096200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.064400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.061300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.056600</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.053200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.050700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.048600</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.051200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.046300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.049900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1776103311.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n⏳ Training started - this may take a while...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m                     )\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3810\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3811\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     ) -> List[Any]:\n\u001b[0;32m--> 212\u001b[0;31m         return parallel_apply(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"# 9. Save the model\nprint(\"\\n💾 Saving fine-tuned model...\")\nmodel.save_pretrained(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)\nprint(f\"✅ Model saved to {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:37.817358Z","iopub.status.idle":"2025-07-23T13:57:37.817889Z","shell.execute_reply.started":"2025-07-23T13:57:37.817711Z","shell.execute_reply":"2025-07-23T13:57:37.817727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 10. Inference section\nprint(\"\\n🔍 Testing inference on example sentences...\")\nprint(\"=\" * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:37.819074Z","iopub.status.idle":"2025-07-23T13:57:37.819405Z","shell.execute_reply.started":"2025-07-23T13:57:37.819246Z","shell.execute_reply":"2025-07-23T13:57:37.819260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the fine-tuned model for inference\nprint(\"Loading fine-tuned model for inference...\")\ninference_model = AutoModelForSeq2SeqLM.from_pretrained(OUTPUT_DIR)\ninference_tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\ninference_model.eval()\n\n# Test examples\nexamples = [\n    \"La iglesia contiene numerosas obras de harte\",\n    \"En esta parroquia tamvién desarrolla alguna de sus actividades\",\n    \"Otras obras notables shon las pinturas del Cavalier d Arpino\",\n    \"Recivió la consideración de parroquia en ES_UN_NUMERO\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:37.820870Z","iopub.status.idle":"2025-07-23T13:57:37.821187Z","shell.execute_reply.started":"2025-07-23T13:57:37.821039Z","shell.execute_reply":"2025-07-23T13:57:37.821052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n🧪 Running inference on test examples:\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:37.821621Z","iopub.status.idle":"2025-07-23T13:57:37.821917Z","shell.execute_reply.started":"2025-07-23T13:57:37.821747Z","shell.execute_reply":"2025-07-23T13:57:37.821759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def correct_spelling(text):\n    inputs = inference_tokenizer(\n        text, \n        return_tensors=\"pt\", \n        max_length=MAX_LENGTH, \n        truncation=True, \n        padding=True\n    )\n    \n    with torch.no_grad():\n        outputs = inference_model.generate(\n            **inputs,\n            max_length=MAX_LENGTH,\n            num_beams=4,\n            early_stopping=True,\n            do_sample=False\n        )\n    \n    corrected = inference_tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return corrected\n\nfor i, example in enumerate(examples, 1):\n    print(f\"\\n{i}. Input:  {example}\")\n    corrected = correct_spelling(example)\n    print(f\"   Output: {corrected}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"✅ Fine-tuning and inference completed successfully!\")\nprint(f\"📁 Model saved in: {OUTPUT_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:37.822928Z","iopub.status.idle":"2025-07-23T13:57:37.823545Z","shell.execute_reply.started":"2025-07-23T13:57:37.823372Z","shell.execute_reply":"2025-07-23T13:57:37.823389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optional: Quick evaluation on test set\nprint(\"\\n📊 Optional: Quick evaluation on test set...\")\ntest_files = [\"test_medicine.tsv\", \"test_wikicorpus.tsv\"]\n\nfor test_file in test_files:\n    test_path = os.path.join(DATA_DIR, test_file)\n    if os.path.exists(test_path):\n        print(f\"\\nLoading {test_file}...\")\n        test_df = pd.read_csv(test_path, delimiter='\\t').dropna()\n        \n        if len(test_df) > 0:\n            # Test on first 5 samples\n            print(f\"Testing on first 5 samples from {test_file}:\")\n            for idx in range(min(5, len(test_df))):\n                source = test_df.iloc[idx]['source']\n                target = test_df.iloc[idx]['target']\n                predicted = correct_spelling(source)\n                \n                print(f\"\\n  Sample {idx+1}:\")\n                print(f\"    Source:    {source}\")\n                print(f\"    Target:    {target}\")\n                print(f\"    Predicted: {predicted}\")\n                print(f\"    Match:     {'✅' if predicted.strip() == target.strip() else '❌'}\")\n    else:\n        print(f\"❌ {test_file} not found for evaluation\")\n\nprint(\"\\n🎉 Script execution completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T13:57:37.824032Z","iopub.status.idle":"2025-07-23T13:57:37.824327Z","shell.execute_reply.started":"2025-07-23T13:57:37.824183Z","shell.execute_reply":"2025-07-23T13:57:37.824196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}